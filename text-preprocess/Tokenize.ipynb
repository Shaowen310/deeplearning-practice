{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK word tokenize, sentence -> list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"The quick brown fox jumps over the lazy dog.\"\n",
    "words = nltk.word_tokenize(sentence)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SELECT', 'LAT_N', ',', 'CITY', ',', 'TEMP_F', 'FROM', 'STATS', ',', 'STATION', 'WHERE', 'MONTH', '=', '7', 'AND', 'STATS.ID', '=', 'STATION.ID', 'ORDER', 'BY', 'TEMP_F', ';']\n"
     ]
    }
   ],
   "source": [
    "sql_text = '''SELECT LAT_N, CITY, TEMP_F\n",
    "FROM STATS, STATION\n",
    "WHERE MONTH = 7\n",
    "AND STATS.ID = STATION.ID\n",
    "ORDER BY TEMP_F;'''\n",
    "\n",
    "words = nltk.word_tokenize(sql_text)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit([1 2 2 6])\n",
      "classes: [1 2 6]\n",
      "transform([1 1 2 6]) [0 0 1 2]\n",
      "inverse_transform([0 0 1 2]) [1 1 2 6]\n"
     ]
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "le.fit([1, 2, 2, 6])\n",
    "print(\"fit([1 2 2 6])\")\n",
    "print(\"classes:\", le.classes_)\n",
    "\n",
    "trans_res = le.transform([1, 1, 2, 6])\n",
    "print(\"transform([1 1 2 6])\", trans_res)\n",
    "\n",
    "inv_trans_res = le.inverse_transform([0, 0, 1, 2])\n",
    "print(\"inverse_transform([0 0 1 2])\", inv_trans_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit(['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.'])\n",
      "classes: ['.' 'The' 'brown' 'dog' 'fox' 'jumps' 'lazy' 'over' 'quick' 'the']\n",
      "transform(['quick', 'brown', 'fox']) [8 2 4]\n",
      "inverse_transform([8 2 4]) ['quick' 'brown' 'fox']\n"
     ]
    }
   ],
   "source": [
    "sentence = ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.']\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(sentence)\n",
    "print(\"fit(['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', '.'])\")\n",
    "print(\"classes:\", le.classes_)\n",
    "\n",
    "trans_res = le.transform(['quick', 'brown', 'fox'])\n",
    "print(\"transform(['quick', 'brown', 'fox'])\", trans_res)\n",
    "\n",
    "inv_trans_res = le.inverse_transform([8, 2, 4])\n",
    "print(\"inverse_transform([8 2 4])\", inv_trans_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Missing values\n",
    "\n",
    "ValueError: y contains previously unseen labels: [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "\n",
    "le.fit([1, 2, 2, 6])\n",
    "\n",
    "#trans_res = le.transform([1, 1, 3, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incremental label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class IncrementalLabelEncoder:\n",
    "    def __init__(self):\n",
    "        self.dict = {}\n",
    "        \n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return list(self.dict.keys())\n",
    "    \n",
    "    def partial_fit(self, y):\n",
    "        y_uniq = np.unique(y)\n",
    "        for elem in y_uniq:\n",
    "            if elem not in self.dict:\n",
    "                self.dict[elem] = len(self.dict)\n",
    "                \n",
    "    def transform(self, y):\n",
    "        return [self.dict[elem] for elem in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classes: ['.', 'The', 'brown', 'dog', 'fox', 'jumps', 'lazy', 'over', 'quick', 'the', 'camera', 'caught', 'on', 'was']\n",
      "transform(['quick', 'brown', 'fox']) [8, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "sentences = ['The quick brown fox jumps over the lazy dog.', 'The lazy dog was caught on camera.']\n",
    "\n",
    "sentence_words = [ nltk.word_tokenize(sentence) for sentence in sentences ]\n",
    "\n",
    "ile = IncrementalLabelEncoder()\n",
    "\n",
    "for words in sentence_words:\n",
    "    ile.partial_fit(words)\n",
    "    \n",
    "print(\"classes:\", ile.classes_)\n",
    "\n",
    "trans_res = ile.transform(['quick', 'brown', 'fox'])\n",
    "print(\"transform(['quick', 'brown', 'fox'])\", trans_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sklearn\n",
    "\n",
    "Should be used along with LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X\n",
      " [[ 0  1  2  3  4]\n",
      " [ 5  6  7  8  9]\n",
      " [10 11 12 13 14]]\n",
      "X label encoded\n",
      " [[0 0 0 0 0]\n",
      " [1 1 1 1 1]\n",
      " [2 2 2 2 2]]\n",
      "X one-hot encoded\n",
      " [[1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "X = np.arange(15).reshape(3, 5)\n",
    "print(\"X\\n\", X)\n",
    "\n",
    "le = LabelEncoder()\n",
    "X_le = np.apply_along_axis(le.fit_transform, 0, X)\n",
    "print(\"X label encoded\\n\", X_le)\n",
    "\n",
    "oe = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "X_oe = oe.fit_transform(X_le)\n",
    "print(\"X one-hot encoded\\n\", X_oe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random vector encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label to random vector map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def init_label_rand_vec_map(length, vec_dim):\n",
    "    return np.random.random((length, vec_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
